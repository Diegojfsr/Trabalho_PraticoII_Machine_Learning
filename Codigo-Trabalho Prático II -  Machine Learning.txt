
Trabalho Prático II -  Machine Learning .ipynb


###Step1 : Preparação para previsão
#importar bibliotecas
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier

# ############################################################


#dataset = pd.read_csv('Dados_compra.csv')
#url='https://github.com/gustavowillam/ML/blob/main/datasets/classifier/Telecom_Users.csv?raw=true'
#df = pd.read_csv(url)

#ler dados de treino e dados de teste
#data = pd.read_csv('/kaggle/input/titanic/train.csv', engine='python', encoding='utf-8')
#test = pd.read_csv('/kaggle/input/titanic/test.csv', engine='python', encoding='utf-8')

train = pd.read_csv('https://github.com/Diegojfsr/Trabalho_PraticoII_Machine_Learning/blob/main/train.csv?raw=true')
test = pd.read_csv('https://github.com/Diegojfsr/Trabalho_PraticoII_Machine_Learning/blob/main/test.csv?raw=true')

# ############################################################


#Verificar os dados.
#data

#Verificar os dados.
train

# ############################################################


###Step2 : Remodelar conjuntos de dados.

#preencher os valores ausentes dos conjuntos de dados usando o método "bfill".
#data = data.fillna(method='bfill')
#data = data.fillna(method='ffill')
#test = test.fillna(method='bfill')
#test = test.fillna(method='ffill')

#preencher os valores ausentes dos conjuntos de dados usando o método "bfill".
train = train.fillna(method='bfill')
train = train.fillna(method='ffill')
test = test.fillna(method='bfill')
test = test.fillna(method='ffill')

# ############################################################


#Alterar os números de cabine como C-100, A-200 para A, C.  
#data['Cabin']=data['Cabin'].str[0:1]
#test['Cabin']=test['Cabin'].str[0:1]

#Alterar os números de cabine como C-100, A-200 para A, C.  
train['Cabin']=train['Cabin'].str[0:1]
test['Cabin']=test['Cabin'].str[0:1]

# ############################################################

#data
train

# ############################################################


#Codificar as 3 colunas em recursos categóricos 
#le = LabelEncoder()
#le = le.fit(data['Sex'])
#data['Sex'] = le.transform(data['Sex'])
#test['Sex'] = le.transform(test['Sex'])
#le = le.fit(data['Cabin'])
#data['Cabin'] = le.transform(data['Cabin'])
#test['Cabin'] = le.transform(test['Cabin'])
#le = le.fit(data['Embarked'])
#data['Embarked'] = le.transform(data['Embarked'])
#test['Embarked'] = le.transform(test['Embarked'])

#Codificar as 3 colunas em recursos categóricos 
le = LabelEncoder()
le = le.fit(train['Sex'])
train['Sex'] = le.transform(train['Sex'])
test['Sex'] = le.transform(test['Sex'])
le = le.fit(train['Cabin'])
train['Cabin'] = le.transform(train['Cabin'])
test['Cabin'] = le.transform(test['Cabin'])
le = le.fit(train['Embarked'])
train['Embarked'] = le.transform(train['Embarked'])
test['Embarked'] = le.transform(test['Embarked'])

# ############################################################


#data
train

# ############################################################


#x_train= data.iloc[:,[2,4,5,6,7,9,10,11]].astype("int64")
#y_train= data.iloc[:,[1]].astype("int64")

x_train= train.iloc[:,[2,4,5,6,7,9,10,11]].astype("int64")
y_train= train.iloc[:,[1]].astype("int64")


# ############################################################

x_train

y_train

# ############################################################


###Step3: verificar a correlação no conjunto de dados.
check_df=pd.concat([x_train,y_train],axis=1)
check_df.corr()

# ############################################################

###Usando colunas inteiras.
x_test=test.iloc[:,[1,3,4,5,6,8,9,10]]
x_test


# ############################################################

#Normalizar dados de 0 a 1 usando StandardScaler
x_train = StandardScaler().fit_transform(x_train)
x_test = StandardScaler().fit_transform(x_test)


# ############################################################

###Step4 :Ajustar este conjunto de dados remodelado.

#Let's fit and predict.
forest = RandomForestClassifier(n_estimators=200, random_state=2, max_depth=300)
forest.fit(x_train, y_train)
model_score=forest.score(x_train, y_train)

# ############################################################

print("A pontuação nos dados de rastreamento deste modelo de aprendizado de máquina é: ",model_score,"!")


# ############################################################

###Step5 :Fazer uma previsão
y_pred=forest.predict(x_test)

# ############################################################


#y_pred2= pd.DataFrame(y_pred)
#y_pred2["Survived"]= y_pred2[0]
#y_pred2=y_pred2.iloc[:,[1]].astype("int")
#y_pred2

y_pred2= pd.DataFrame(y_pred)
y_pred2["Survived"]= y_pred2[0]
y_pred2=y_pred2.iloc[:,[1]].astype("int")
y_pred2

# ############################################################

###Step6 :Compilar um arquivo de submissão.
#Conectar dados de teste e dados de previsão
result=pd.concat([test,y_pred2],axis=1)
result=result.iloc[:,[0,11]]
result

# ############################################################

#criar um arquivo csv de saída como submit.csv
result.to_csv('submission_final.csv', index=False)
print('submission_final.csv foi salvo!')

#submit_final.csv foi salvo!






































